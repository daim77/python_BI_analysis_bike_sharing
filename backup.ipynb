{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nacte uklozena data ze souboru csv\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "bikes_df = \\\n",
    "    pd.read_csv('tables/bikes.csv', sep='\\t').iloc[:, 1:]\n",
    "weather_df = \\\n",
    "    pd.read_csv('tables/weather.csv', sep='\\t').iloc[:, 1:]\n",
    "stations_id_df = \\\n",
    "    pd.read_csv('tables/stations_id.csv', sep='\\t').iloc[:, 1:]\n",
    "full_data_df = pd.read_csv('tables/full_data.csv', sep='\\t').iloc[:, 1:]\n",
    "\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "bikes_df['started_at'] = pd.to_datetime(bikes_df['started_at'])\n",
    "bikes_df['ended_at'] = pd.to_datetime(bikes_df['ended_at'])\n",
    "bikes_df['wx_date'] = pd.to_datetime(bikes_df['wx_date'])\n",
    "\n",
    "full_data_df['started_at'] = pd.to_datetime(full_data_df['started_at'])\n",
    "full_data_df['wx_date'] = pd.to_datetime(full_data_df['wx_date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "# Python data analysis project - Bike sharing problem\n",
    "***\n",
    "## FIRST - RECEIVING DATA\n",
    "Connection to DB and download data from ENGETO db.\n",
    "\n",
    "I don't loaded: full name of stations, station description and duration\n",
    "\n",
    "Duration was calculated.\n",
    "\n",
    "Initialy two DataFrames are created.\n",
    "1. BIKES_DF with journey data\n",
    "2. WEATHER_DF with weather measurements for Edinbourgh city"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sqlalchemy as db\n",
    "\n",
    "\n",
    "file1 = open('/Users/martindanek/Documents/programovani/engeto_password.txt', \"r\")\n",
    "user_data = eval(file1.read())\n",
    "file1.close()\n",
    "\n",
    "user = user_data[0][0]\n",
    "password = user_data[0][1]\n",
    "\n",
    "conn_string = f\"mysql+pymysql://{user}:{password}@data.engeto.com/data\"\n",
    "engeto_conn = db.create_engine(conn_string, echo=True)\n",
    "\n",
    "db_connection = engeto_conn.connect()\n",
    "\n",
    "bikes_df = pd.read_sql_query(\n",
    "    \"SELECT \"\n",
    "    \"started_at, ended_at, \"\n",
    "    \"start_station_id, start_station_latitude, start_station_longitude, \"\n",
    "    \"end_station_id, end_station_latitude, end_station_longitude \"\n",
    "    \"FROM edinburgh_bikes;\",\n",
    "    engeto_conn, parse_dates=True\n",
    ")\n",
    "\n",
    "weather_df = pd.read_sql_query(\n",
    "    \"SELECT \"\n",
    "    \"date, time, temp, feels, wind, gust, rain, humidity, cloud, vis \"\n",
    "    \"FROM edinburgh_weather;\",\n",
    "    engeto_conn, parse_dates=True)\n",
    "\n",
    "db_connection.close()\n",
    "\n",
    "weather_df.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SECOND - DATA PREPARATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Trim dates for weather and bike dataset to same period**\n",
    "\n",
    "Date range for BIKES dataset\n",
    "\n",
    "min date = 2018-09-15 | max date = 2020-10-30"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df.head()\n",
    "print(bikes_df['started_at'].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Date range for WEATHER dataset\n",
    "\n",
    "min date = 2018-09-01 | max date = 2020-10-31\n",
    "\n",
    "weather dataset has longer period than needed for further relevant analysis.\n",
    "\n",
    "Useless data droped."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_df.head()\n",
    "print(weather_df['date'].describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selection = (weather_df['date'] >= '2018-09-15') & (weather_df['date'] <= '2020-10-30')\n",
    "weather_df = weather_df.loc[selection, :]\n",
    "weather_df['date'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**weather DataFrame preparation**\n",
    "\n",
    "separate numeric values from units\n",
    "\n",
    "drop origin previous columns\n",
    "\n",
    "convert directions into azimuth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_df['wind_speed_km_h'] = weather_df['wind'].str.split(' ').str[0]\n",
    "weather_df['wind_direction_deg'] = weather_df['wind'].str.split(' ').str[3]\n",
    "weather_df['gust_km_h'] = weather_df['gust'].str.split(' ').str[0]\n",
    "weather_df['temp_c'] = weather_df['temp'].str.split(' ').str[0]\n",
    "weather_df['feels_c'] = weather_df['feels'].str.split(' ').str[0]\n",
    "weather_df['rain_mm'] = weather_df['rain'].str.split(' ').str[0]\n",
    "weather_df['humidity_%'] = weather_df['humidity'].str.rstrip('%')\n",
    "weather_df['cloudiness_%'] = weather_df['cloud'].str.rstrip('%')\n",
    "\n",
    "weather_df.drop(['wind', 'gust', 'temp', 'feels', 'rain', 'humidity', 'cloud'], axis=1, inplace=True)\n",
    "\n",
    "weather_df['wind_direction_deg'] = weather_df['wind_direction_deg'].map({\n",
    "    'N': 0, 'NNE': 22.5, 'NE': 45, 'ENE': 67.5, 'E': 90,\n",
    "    'ESE': 112.5, 'SE': 135, 'SSE': 157.5, 'S': 180,\n",
    "    'SSW': 202.5, 'SW': 225, 'WSW': 247.5, 'W': 270,\n",
    "    'WNW': 292.5, 'NW': 315, 'NNW': 337.5})\n",
    "\n",
    "weather_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*wind directions unique*\n",
    "\n",
    "12 values in all quadrants."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(weather_df['wind_direction_deg'].unique())\n",
    "x = weather_df['wind_direction_deg'].unique()\n",
    "y = [5 for num in range(len(x))]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='polar')\n",
    "ax.scatter(x, y)\n",
    "ax.set_theta_zero_location(\"N\")  # theta=0 at the top\n",
    "ax.set_theta_direction(-1)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**weather and bikes 'date' manipulation**\n",
    "\n",
    "weather => date and hour into one string\n",
    "\n",
    "Weather measurements is only 8times per day.\n",
    "\n",
    "bikes => creating nearest 'date' of 'start_ride_at' to weather measurement as \"wx_date\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_df.loc[:, 'date'] = pd.to_datetime(\n",
    "    weather_df.date.astype(str) + ' ' + weather_df.time.astype(str)\n",
    ")\n",
    "weather_df.drop('time', axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df['wx_date'] = pd.to_datetime(bikes_df['started_at'].dt.date) \\\n",
    "                      + pd.to_timedelta(\n",
    "    round(bikes_df['started_at'].dt.hour / 3, 0) * 3, unit='h')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Weather_df: \\t',weather_df['date'].head(2))\n",
    "print('=' * 20)\n",
    "print('Bikes_df: \\t',bikes_df.loc[:2, ['started_at', 'wx_date']])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**convert columns to correct dtypes**\n",
    "\n",
    "important is convert numbers from strings and date from string to daytime format."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weather_df = weather_df.astype({'wind_speed_km_h': int,\n",
    "                                \"gust_km_h\": int,\n",
    "                                'temp_c': int,\n",
    "                                'feels_c': int,\n",
    "                                'rain_mm': float,\n",
    "                                'humidity_%': int,\n",
    "                                'cloudiness_%': int,\n",
    "                                'wind_direction_deg': float})\n",
    "\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])\n",
    "\n",
    "bikes_df = bikes_df.astype({'start_station_id': int,\n",
    "                                \"start_station_latitude\": float,\n",
    "                                'start_station_longitude': float,\n",
    "                                'end_station_id': int,\n",
    "                                'end_station_latitude': float,\n",
    "                                'end_station_longitude': float\n",
    "                                })\n",
    "\n",
    "bikes_df['started_at'] = pd.to_datetime(bikes_df['started_at'])\n",
    "bikes_df['ended_at'] = pd.to_datetime(bikes_df['ended_at'])\n",
    "bikes_df['wx_date'] = pd.to_datetime(bikes_df['wx_date'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('bikes_df:\\n\\n', bikes_df.dtypes)\n",
    "print()\n",
    "print('weather_df:\\n\\n',weather_df.dtypes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**wind speed and gust dependency**\n",
    "\n",
    "Hypothesis => only gust as demand indicator is important (due to riders' feelings)\n",
    "\n",
    "WIND column are dropped due to correlation - As expected stronger wind mean stronger gust"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = weather_df.loc[:, ['wind_speed_km_h', 'gust_km_h']]\n",
    "df.plot.scatter('wind_speed_km_h', 'gust_km_h', figsize=(12, 6), marker='x', color='blue')\n",
    "\n",
    "weather_df.drop(['wind_speed_km_h'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**temp and feels temp dependency**\n",
    "\n",
    "Hypothesis => only feels over temp is important\n",
    "\n",
    "TEMP column are dropped due to correlation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = weather_df.loc[: ,['temp_c', 'feels_c']]\n",
    "df.plot.scatter('temp_c', 'feels_c', figsize=(12, 6), marker='x', color='red')\n",
    "\n",
    "weather_df.drop(['temp_c'], axis=1, inplace=True)\n",
    "\n",
    "weather_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**create set of stations with coordinates and set proper station elevation**\n",
    "\n",
    "result is dataset named STATION_ID_DF\n",
    "\n",
    "Total amount of unique stations ID in dataset is 199"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(bikes_df.loc[:, ['start_station_id', 'start_station_latitude', 'start_station_longitude']])\\\n",
    "    .drop_duplicates('start_station_id', keep='first')\\\n",
    "    .rename(columns={'start_station_id': 'station_id',\n",
    "                     'start_station_latitude': 'lat',\n",
    "                     'start_station_longitude': 'long'})\n",
    "\n",
    "df2 = bikes_df.loc[:, ['end_station_id', 'end_station_latitude', 'end_station_longitude']]\\\n",
    "    .drop_duplicates('end_station_id', keep='first')\\\n",
    "    .rename(columns={'end_station_id': 'station_id',\n",
    "                     'end_station_latitude': 'lat',\n",
    "                     'end_station_longitude': 'long'})\n",
    "stations_id_df = pd.merge(df2, df1, left_on='station_id', right_on='station_id', how='left')\n",
    "stations_id_df = stations_id_df.drop(['lat_y', 'long_y'], axis=1).sort_index(ascending=False)\n",
    "stations_id_df = stations_id_df.rename(columns={'lat_x': 'lat', 'long_x': 'long'})\n",
    "stations_id_df.set_index('station_id', inplace=True)\n",
    "stations_id_df.sort_index(ascending=True, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stations_id_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "get elevation data for bike station with OpenStreetMap API\n",
    "\n",
    "API is public with no registration. Lat, Long is required parameter. Output is JSON"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "def get_elevation_osm(lat, long):\n",
    "    osm_api = \\\n",
    "        f\"https://api.open-elevation.com/api/v1/lookup?locations={lat},{long}\"\n",
    "    response = requests.get(osm_api)\n",
    "    elevation = response.json()\n",
    "    return elevation['results'][0]['elevation']\n",
    "\n",
    "\n",
    "stations_id_df['elev'] = stations_id_df.iloc[:]\\\n",
    "    .apply(lambda x: get_elevation_osm(x['lat'], x['long']), axis=1)\n",
    "\n",
    "stations_id_df.reset_index(inplace=True)\n",
    "stations_id_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Calculate journey defference elevation**\n",
    "\n",
    "uphill == delta_elev is positive\n",
    "\n",
    "downhill == delta_elev is negative\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elev_dict = pd.Series(stations_id_df['elev']\n",
    "                      .values, index=stations_id_df.station_id).to_dict()\n",
    "\n",
    "bikes_df['start_elev'] = bikes_df['start_station_id'].map(elev_dict)\n",
    "bikes_df['end_elev'] = bikes_df['end_station_id'].map(elev_dict)\n",
    "\n",
    "bikes_df['delta_elev'] = bikes_df['end_elev'] - bikes_df['start_elev']\n",
    "\n",
    "bikes_df[['delta_elev']].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Calculation journeys' distances and initial great circle bearings and duration of one journey**\n",
    "\n",
    "3 values are extreme. End stations are in Liverpool with distance about 250km!!!\n",
    "\n",
    "NOTE: Length of Edinbourhg city is roughly 13km wide"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def get_distance(lat1, long1, lat2, long2):\n",
    "    if lat1 == lat2 and long1 == long2:\n",
    "        return 0\n",
    "\n",
    "    RADIUS = 6371\n",
    "\n",
    "    a_lat = math.radians(lat1)\n",
    "    b_lat = math.radians(lat2)\n",
    "    delta_long = abs(math.radians(long2) - math.radians(long1))\n",
    "\n",
    "    delta = math.acos(\n",
    "        math.sin(a_lat) * math.sin(b_lat)\n",
    "        + math.cos(a_lat) * math.cos(b_lat)\n",
    "        * math.cos(delta_long)\n",
    "    )\n",
    "    return round(RADIUS * delta, 2)\n",
    "\n",
    "\n",
    "def get_heading(lat1, long1, lat2, long2):\n",
    "    if (lat1 == lat2) and (long1 == long2):\n",
    "        return 999\n",
    "    # point1\n",
    "    lat1 = math.radians(lat1)\n",
    "    long1 = math.radians(long1)\n",
    "    # point2\n",
    "    lat2 = math.radians(lat2)\n",
    "    long2 = math.radians(long2)\n",
    "\n",
    "    delta_long = long2 - long1\n",
    "\n",
    "    bearing = math.atan(\n",
    "        math.cos(lat2) * math.sin(delta_long)\n",
    "        / (\n",
    "                math.cos(lat1) * math.sin(lat2)\n",
    "                - math.sin(lat1) * math.cos(lat2) * math.cos(delta_long)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    bearing = math.degrees(bearing)\n",
    "\n",
    "    if bearing == 0 and math.copysign(-1, bearing) == -1:\n",
    "        bearing = 180\n",
    "    elif (lat1 > lat2) & (long1 > long2):\n",
    "        bearing += 180\n",
    "    elif (lat1 <= lat2) & (long1 > long2):\n",
    "        bearing += 360\n",
    "    else:\n",
    "        bearing = int(divmod(bearing, 180)[1])\n",
    "    return int(round(bearing, 0))\n",
    "\n",
    "\n",
    "bikes_df['dist_km'] = bikes_df.iloc[:, :]\\\n",
    "    .apply(lambda x: get_distance(x['start_station_latitude'],\n",
    "                                  x['start_station_longitude'],\n",
    "                                  x['end_station_latitude'],\n",
    "                                  x['end_station_longitude']), axis=1)\n",
    "\n",
    "bikes_df['heading_deg'] = bikes_df.iloc[:, :]\\\n",
    "    .apply(lambda x: get_heading(x['start_station_latitude'],\n",
    "                                 x['start_station_longitude'],\n",
    "                                 x['end_station_latitude'],\n",
    "                                 x['end_station_longitude']), axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df['duration_s'] = bikes_df['ended_at'] - bikes_df['started_at']\n",
    "bikes_df['duration_s'] = bikes_df['duration_s'].dt.total_seconds()\n",
    "\n",
    "bikes_df[['duration_s']].head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**column with week day info added**\n",
    "\n",
    "coding 0: Monday | 6: Sunday"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df['day_of_week'] = bikes_df['started_at'].dt.dayofweek\n",
    "\n",
    "bikes_df['day_of_week'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Join data sets into one big dataFrame**\n",
    "\n",
    "FULL_DATA dataset created and duplicated columns are dropped"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_data_df = pd.merge(bikes_df, weather_df, left_on='wx_date', right_on='date', how='left')\n",
    "\n",
    "full_data_df.drop('date', axis=1, inplace=True)\n",
    "full_data_df.drop('ended_at', axis=1, inplace=True)\n",
    "\n",
    "full_data_df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_data_df.head(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## THIRD - VISUAL ANALYSIS and STAT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Season effect**\n",
    "\n",
    "Amounts of rides per month\n",
    "\n",
    "We can devide data into two groups:\n",
    "1. warm period from May till October\n",
    "2. cold period from November till April"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = bikes_df['started_at'].dt.month\n",
    "df.plot.hist(df,\n",
    "             figsize=(12, 6), color='orange', bins=12,\n",
    "             legend='True', title='Aggregated Month rides',\n",
    "             xticks=[num for num in range(1, 13)], edgecolor='k', fontsize='20');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**wind**\n",
    "\n",
    "For purpose together analyze wind and heading, it is necessary to convert heading into wind interval measurement.\n",
    "e.g. heading 001 onto north etc.\n",
    "\n",
    "Wind has two peaks = westbound wind and eastbound wind regardless season. As well as riders' heading.\n",
    "Further below we can see that heading is influenced by geografically.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def heading_convert(x):\n",
    "    if x % 22.5 > 11.25:\n",
    "        return (x // 22.5) * 22.5 + 22.5\n",
    "    else:\n",
    "        return (x // 22.5) * 22.5\n",
    "\n",
    "\n",
    "selection_c = (full_data_df['wx_date'].dt.month >= 11) | (full_data_df['wx_date'].dt.month <= 4)\n",
    "selection_w = (full_data_df['wx_date'].dt.month <= 10) & (full_data_df['wx_date'].dt.month >= 5)\n",
    "\n",
    "# warm period\n",
    "df_w_w = pd.DataFrame(full_data_df.loc[selection_w, ['wind_direction_deg']].value_counts().sort_index()).reset_index()\n",
    "df_w_w.rename(columns={0: 'wind_freq'}, inplace=True)\n",
    "\n",
    "df_w_h = pd.DataFrame(full_data_df.loc[selection_w, ['heading_deg']]\n",
    "                   .apply(lambda x: heading_convert(x['heading_deg']), axis=1)\n",
    "                   .value_counts().sort_index()).reset_index()\n",
    "df_w_h.rename(columns={0: 'hdg_freq', 'index': 'heading_deg'}, inplace=True)\n",
    "\n",
    "df_w = pd.merge(df_w_h, df_w_w, left_on='heading_deg', right_on='wind_direction_deg')\n",
    "\n",
    "#cold period\n",
    "df_c_w = pd.DataFrame(full_data_df.loc[selection_c, ['wind_direction_deg']].value_counts().sort_index()).reset_index()\n",
    "df_c_w.rename(columns={0: 'wind_freq'}, inplace=True)\n",
    "\n",
    "df_c_h = pd.DataFrame(full_data_df.loc[selection_c, ['heading_deg']]\n",
    "                   .apply(lambda x: heading_convert(x['heading_deg']), axis=1)\n",
    "                   .value_counts().sort_index()).reset_index()\n",
    "df_c_h.rename(columns={0: 'hdg_freq', 'index': 'heading_deg'}, inplace=True)\n",
    "\n",
    "df_c = pd.merge(df_c_h, df_c_w, left_on='heading_deg', right_on='wind_direction_deg')\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "fig.suptitle('Season period', fontsize=30)\n",
    "ax1.plot(df_w['wind_direction_deg'], df_w['wind_freq'], color='b')\n",
    "ax1.plot(df_w['wind_direction_deg'], df_w['hdg_freq'], color='r')\n",
    "ax1.legend(['wind', 'heading'])\n",
    "ax1.set_title('May till October', fontsize=30)\n",
    "ax1.set_ylabel('frequency', fontsize=20)\n",
    "\n",
    "ax2.plot(df_c['wind_direction_deg'], df_c['wind_freq'], color='b')\n",
    "ax2.plot(df_c['wind_direction_deg'], df_c['hdg_freq'], color='r')\n",
    "ax2.set_title('November till April', fontsize=30)\n",
    "ax2.legend(['wind', 'heading'])\n",
    "ax2.set_xlabel('degrees', fontsize=20)\n",
    "ax2.set_ylabel('frequency', fontsize=20)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "scatter diagram heading by wind direction\n",
    "\n",
    "There is only first 5% of rides and it is visible that heading of riders is independent on wind direction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(full_data_df.loc[:, ['heading_deg']].apply(lambda x: heading_convert(x['heading_deg']), axis=1))\n",
    "df1.rename(columns={0: 'heading_deg'}, inplace=True)\n",
    "df2 = pd.DataFrame(full_data_df.loc[:, ['wind_direction_deg']])\n",
    "\n",
    "df = pd.merge(df1, df2, left_index=True, right_index=True)\n",
    "\n",
    "df.iloc[:17049, :].plot.scatter(x='heading_deg', y='wind_direction_deg', figsize=(12, 6));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Rain**\n",
    "\n",
    "Average rain for all recorded journeys is about 18% less than for weather measurement in our period.\n",
    "\n",
    "Also STD is less which can show that riders prefer more stable weather and no rainy weather.\n",
    "\n",
    "75% riders meet only drizzle.\n",
    "\n",
    "__Hypothesis: \"Only outliers can momentarily influence bikes demand \"__\n",
    "\n",
    "There is 8 measurement per day. We have 776days to analyze, so we have 6209 weather measurements.\n",
    "\n",
    "68 % measurement detected no rain. which covers 64% rides in zero rain.\n",
    "\n",
    "\n",
    "1mm rain is very week. It covers 90% of measurements and 92% rides\n",
    "\n",
    "2.5mm is officially classified as \"light rain\" and only 4.85% of weather measurements detected stronger rain.\n",
    "This rain covers only 3.4% rides\n",
    "\n",
    "In absolute figures: 301 measurements detected rain stronger than light and this period covers 11605 rides\n",
    "\n",
    "Outliers all data above 1.7 mm per hour are 5% of total rides - level of significance 95%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('WEATHER DATA')\n",
    "print(weather_df['rain_mm'].describe())\n",
    "print()\n",
    "print('No rain measurements in %: ',\n",
    "      weather_df.loc[weather_df['rain_mm'] == 0, 'rain_mm'].count()/6209 * 100)\n",
    "print('1mm- rain measurements in %: ',\n",
    "      weather_df.loc[weather_df['rain_mm'] <= 1, 'rain_mm'].count()/6209 * 100)\n",
    "print('2.5mm+ rain measurements in %: ',\n",
    "      weather_df.loc[full_data_df['rain_mm'] > 2.5, 'rain_mm'].count()/6209 * 100)\n",
    "print()\n",
    "\n",
    "print('FULL DATA')\n",
    "print(full_data_df['rain_mm'].describe())\n",
    "print()\n",
    "print('No rain rides: ',\n",
    "      full_data_df.loc[full_data_df['rain_mm'] == 0, 'rain_mm'].count()/340986 * 100)\n",
    "print('1mm- rainy rides: ',\n",
    "      full_data_df.loc[full_data_df['rain_mm'] <= 1, 'rain_mm'].count()/340986 * 100)\n",
    "print('2.5mm+ rainy rides: ',\n",
    "      full_data_df.loc[full_data_df['rain_mm'] > 2.5, 'rain_mm'].count())\n",
    "print('rides performed in 2.5mm+ rain in %: ',\n",
    "      full_data_df.loc[full_data_df['rain_mm'] > 2.5, 'rain_mm'].count()/340986 * 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "quantiles\n",
    "\n",
    "99% rides are performed of rain interval <0, 5mm>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q_hi = full_data_df['rain_mm'].quantile(0.99)\n",
    "q_low = full_data_df['rain_mm'].quantile(0.01)\n",
    "print('level of significance 0.99: ', q_hi)\n",
    "print('level of significance 0.01: ', q_low)\n",
    "\n",
    "full_data_df.loc[(full_data_df['rain_mm'] <= q_hi) & (full_data_df['rain_mm'] >= q_low), ['rain_mm']]\\\n",
    "    .boxplot(grid=False, figsize=(12,12));"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "rain characteristics by months on level of significance 0.99\n",
    "\n",
    "weather is mostly with drizzle.\n",
    "\n",
    "The driest month is April.\n",
    "\n",
    "And in general, 75% of all rides is done with rain less than 0.3.mm / hr\n",
    "And max average rain in month is 0.38 in July.\n",
    "\n",
    "Again in \"count\" column we can see more busy months - May till October. This months are also moister.\n",
    "\n",
    "Rain itself has no influance on demand. Important is it momentarily stregth."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "selection = (full_data_df['rain_mm'] <= q_hi) & (full_data_df['rain_mm'] >= q_low)\n",
    "\n",
    "full_data_df.loc[selection, :].groupby(full_data_df['wx_date'].dt.month)['rain_mm'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot mean rain by month\n",
    "\n",
    "and count days with no rain"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1 = full_data_df.loc[(full_data_df['rain_mm'] <= q_hi) & (full_data_df['rain_mm'] >= q_low), :]\n",
    "\n",
    "df1.groupby(df1['wx_date'].dt.month)['rain_mm'].mean()\\\n",
    "    .plot(\n",
    "    legend=True,\n",
    "    figsize=(12,6),\n",
    "    title='mean rain by month without extreme',\n",
    "    label='mean rain in mm by month',\n",
    "    xlabel='MONTH',\n",
    "    ylabel='rain [mm]');\n",
    "\n",
    "total = df1.shape[0]\n",
    "no_rain = round(df1.loc[df1['rain_mm'] == 0, ['rain_mm']].count() / total * 100, 2)\n",
    "print('No rainy rides in : ' + str(no_rain.values[0]) + ' %' )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Rain distribution is significantly positively skewnessed and leptokurtic on level of significance 0.99\n",
    "\n",
    "This effect comes from characteristic weather for Edinburgh - mostly drizzle, and riders accept this"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1['rain_mm']\\\n",
    "    .plot.hist(figsize=(12, 6), color='blue', bins=20, title='rain_mm');"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above maximum of averages monthly rain (0.38 in July) is done only 53835. Which represents 15.8% rides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df1.loc[df1['rain_mm'] > 0.38, ['rain_mm']].count()[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "round(df1.loc[df1['rain_mm'] > 0.38, ['rain_mm']].count()[0] / full_data_df.shape[0] * 100, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "problem of outliers in rain data\n",
    "\n",
    "Theory of Outliers > (Qiii + 3 * Q)\n",
    "\n",
    "TOTAL Amount of rides:\n",
    "- outlier Qiii + 3 * Q =  0.8 mm/hr and more\n",
    "- 31772 rides\n",
    "- 9.3% of total traffic"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "r_d = full_data_df['rain_mm'].describe()\n",
    "r_d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = r_d['75%'] + 3 * (r_d['75%'] - r_d['25%'])\n",
    "print(f'outliers above: {x} mm/ hr')\n",
    "\n",
    "print('Amount of outliers:',\n",
    "      full_data_df.loc[full_data_df['rain_mm'] > r_d['75%'] + 3 * (r_d['75%'] - r_d['25%']),\n",
    "                       ['rain_mm']]\n",
    "      .count()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**jurney delta elevation, distance, duration, heading, histogram**\n",
    "\n",
    "prefered are:\n",
    "- downhills rides\n",
    "- shorter rides\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = full_data_df.loc[:, ['delta_elev']]\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(df['delta_elev'], color='green', bins=10, edgecolor='k', alpha=0.75)\n",
    "ax.set_title('uphill and downhill distributation', fontdict={'fontsize': 30})\n",
    "ax.set_xlabel('meters', fontsize=20)\n",
    "ax.set_ylabel('frequency', fontsize=20);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1km division\n",
    "df = full_data_df.loc[full_data_df['dist_km'] < 8, ['dist_km']]\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(df['dist_km'], color='black', bins=8, edgecolor='black', alpha=0.75)\n",
    "ax.set_title('distance with 1 km division', fontdict={'fontsize': 30})\n",
    "ax.set_xlabel('km', fontsize=20)\n",
    "ax.set_ylabel('frequency', fontsize=20);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 15 deg division\n",
    "df = full_data_df.loc[full_data_df['heading_deg'] < 360, ['heading_deg']]\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(df['heading_deg'], color='blue', bins=24, edgecolor='black', alpha=0.75)\n",
    "ax.set_title('heading with 15 deg division', fontdict={'fontsize': 30})\n",
    "ax.set_xlabel('degrees', fontsize=20)\n",
    "ax.set_ylabel('frequency', fontsize=20);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Day of week - weekly**\n",
    "distribution during total, warm vs cold period"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "df = full_data_df.loc[: ,['day_of_week']]['day_of_week'].tolist()\n",
    "df_w = full_data_df.loc[(full_data_df['started_at'].dt.month >= 5) & (full_data_df['started_at'].dt.month <= 10) ,['day_of_week']]['day_of_week'].tolist()\n",
    "df_c = full_data_df.loc[(full_data_df['started_at'].dt.month <= 4) | (full_data_df['started_at'].dt.month >= 11) ,['day_of_week']]['day_of_week'].tolist()\n",
    "\n",
    "ax.hist([df, df_w, df_c],\n",
    "        bins=7, color=['g', 'r', 'b'], edgecolor='k',\n",
    "        density=False, histtype='bar', alpha=1.0, align='mid',\n",
    "        label=['All data', 'May till October', 'November till April'])\n",
    "\n",
    "ax.set_title('rides per Day of week', fontsize=30)\n",
    "ax.legend()\n",
    "ax.set_xticks([0.3, 1.2, 1.9, 2.9, 3.8, 4.6, 5.5])\n",
    "ax.set_xticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'],\n",
    "                   fontdict={'fontsize': 20, 'rotation': 45})\n",
    "ax.set_yticklabels([i * 10000 for i in range(6)],\n",
    "                   fontdict={'fontsize': 20})\n",
    "ax.set_ylabel('amount of rides', fontdict={'fontsize': 20})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Plotting lat / long stations with elevation**\n",
    "\n",
    "including only Edinburh area (latitude > 55)\n",
    "\n",
    "plotting on map background from mapy.cz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "df = stations_id_df.loc[stations_id_df['lat'] > 55, :]\n",
    "edinburgh_img=mpimg.imread('pics/edinburgh.png')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.imshow(edinburgh_img, extent=[-3.4146247, -3.0246100, 55.8845675, 56.0022333], alpha=0.5)\n",
    "scatter = ax.scatter(df['long'], df['lat'],\n",
    "           s=45, c=df['elev'], cmap='jet',\n",
    "           label = 'Bike stations', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel(\"latitude\", fontsize=20)\n",
    "ax.set_xlabel(\"longitude\", fontsize=20)\n",
    "ax.set_title('Bike stations with their elevation', fontsize=30)\n",
    "ax.legend(fontsize=20)\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(num=5),\n",
    "                    loc=\"upper right\", title=\"elevation [m]\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "rarely used stations IDs 964, 365, 1057, 1056, 1032, 299, 241, 1740, 280, 242"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "list1 = [964, 365, 1057, 1056, 1032, 299, 241, 1740, 280, 242]\n",
    "df = stations_id_df.loc[(stations_id_df['lat'] > 55) & (stations_id_df['station_id'].isin(list1)), :]\n",
    "edinburgh_img=mpimg.imread('pics/edinburgh.png')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.imshow(edinburgh_img, extent=[-3.4146247, -3.0246100, 55.8845675, 56.0022333], alpha=0.5)\n",
    "scatter = ax.scatter(df['long'], df['lat'],\n",
    "           s=45, c=df['elev'], cmap='jet',\n",
    "           label = 'Bike stations', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel(\"latitude\", fontsize=20)\n",
    "ax.set_xlabel(\"longitude\", fontsize=20)\n",
    "ax.set_title('Rarely used stations with their elevation', fontsize=30)\n",
    "ax.legend(fontsize=20)\n",
    "# ax.annotate(df['station_id'], (df['long'], df['lat']))\n",
    "\n",
    "legend1 = ax.legend(*scatter.legend_elements(num=5),\n",
    "                    loc=\"upper right\", title=\"elevation [m]\")\n",
    "ax.add_artist(legend1)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**uphill vs. downhill**\n",
    "\n",
    "There is 83097 uphill rides and 257888 downhill ones. 24% ot total rides in our period creates uphill rides."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = full_data_df.loc[:, ['delta_elev']]\n",
    "print('Downhill amount of rides: ', df.loc[df.delta_elev <= 7, :].shape[0])\n",
    "print('Uphill amount of rides: ', df.loc[df.delta_elev > 7, ['delta_elev']].count()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Rides on heading between 150 and 200 deg**\n",
    "\n",
    "27866 rides are in heading toward city center.\n",
    "\n",
    "This rides have also higher median and average difference elevation than all rides.\n",
    "\n",
    "Chart bellow shows that these uphill rides towards city center are mostly done during warm periods."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = full_data_df.loc[(full_data_df['heading_deg'] >= 150) & (full_data_df['heading_deg'] <= 200), ['delta_elev']]\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "all rides"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = full_data_df['delta_elev']\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = full_data_df.loc[(full_data_df['heading_deg'] >= 150) & (full_data_df['heading_deg'] <= 200), ['wx_date', 'delta_elev']]\n",
    "df = df.groupby(pd.Grouper(key='wx_date', freq='M')).agg({'delta_elev': 'mean'}).reset_index()\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(df['wx_date'], df['delta_elev'], color='k')\n",
    "ax.set_title('Average difference of elevation of riders', fontsize=30)\n",
    "ax.set_xlabel('month', fontsize=20)\n",
    "ax.set_ylabel('delta_elev [m]', fontsize=20)\n",
    "ax.grid(linestyle=\"--\", linewidth=0.5, color='k', zorder=-2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Distance**\n",
    "(distance between START and END stations)\n",
    "\n",
    "Average ride - 1.85 km\n",
    "\n",
    "50% rides are done within distance shorter than 1.53 km\n",
    "\n",
    "Outliers: all rides above 8.22 km\n",
    "\n",
    "Outliers are represented only by 1811 journeys (0.53% all rides in data set)\n",
    "\n",
    "In the next dataset there are excluded outliers values by 3 interquartile range rule"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = bikes_df.dist_km.describe().to_dict()\n",
    "out_hi = result['75%'] + 3 * result['std']\n",
    "out_low = result['25%'] - 3 * result['std']\n",
    "df = bikes_df.loc[(bikes_df.dist_km <= out_hi) & (bikes_df.dist_km >= out_low), ['dist_km']]\n",
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Amount of outliers:', bikes_df.shape[0] - df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Duration analysis**\n",
    "\n",
    "Duration outliers everything above approx 4.32 hrs.\n",
    "\n",
    "75% of rides are done from 1min to 41.88 min.\n",
    "Median is 19.13 min."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(bikes_df[['duration_s']]/60).rename(columns={'duration_s': 'duration_min'}).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "ax = (full_data_df['duration_s']/60)\\\n",
    "    .plot(kind='box',\n",
    "          boxprops=dict(linestyle='-', linewidth=3.5, color='blue'),\n",
    "          flierprops=dict(linestyle='-', linewidth=1.5),\n",
    "          medianprops=dict(linestyle='-', linewidth=2.5, color='r'),\n",
    "          whiskerprops=dict(linestyle=':', linewidth=2.5, color='b'),\n",
    "          capprops=dict(linestyle='-', linewidth=1.5, color='k'),\n",
    "          showfliers=False, grid=True, rot=0, showmeans=True, meanline=True, whis=1.5)\n",
    "\n",
    "ax.grid(False)\n",
    "ax.set_title('Journey durations', fontsize=50)\n",
    "\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xticks([], minor=True)\n",
    "ax.set_yticklabels([])\n",
    "ax.set_yticks([], minor=True)\n",
    "\n",
    "plt.text(1.1, 18, 'median = 19.1 min', {'color': 'r', 'fontsize': 30})\n",
    "plt.text(1.1, 33, 'mean = 31.4 min', {'color': 'g', 'fontsize': 30})\n",
    "plt.text(1.1, 10, '10.3 min', {'color': 'b', 'fontsize': 30})\n",
    "plt.text(1.1, 40, '41.8 min', {'color': 'b', 'fontsize': 30})\n",
    "plt.text(0.8, 0, '1 min', {'color': 'k', 'fontsize': 30})\n",
    "plt.text(0.78, 88, '259 min', {'color': 'k', 'fontsize': 30})\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quantil on level of significance 0.95 is 5460s (approx 1.5 hr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df['duration_s'].quantile(0.95)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Riders ride longer single journeys during weekends regardless of season**\n",
    "\n",
    "warm season May till October (q = 0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cond1 = bikes_df['started_at'].dt.month >= 5\n",
    "cond2 = bikes_df['started_at'].dt.month <= 10\n",
    "cond3 = bikes_df['duration_s'] <= 5460\n",
    "selection = cond1 & cond2 & cond3\n",
    "df = bikes_df.loc[selection, ['duration_s', 'day_of_week']]\n",
    "df.boxplot(by='day_of_week', column=['duration_s'], figsize=(12, 6), grid=False);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "cold season November till April (q = 0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cond1 = bikes_df['started_at'].dt.month <= 4\n",
    "cond2 = bikes_df['started_at'].dt.month >= 11\n",
    "cond3 = bikes_df['duration_s'] <= 5460\n",
    "selection = (cond1 | cond2) & cond3\n",
    "df = bikes_df.loc[selection, ['duration_s', 'day_of_week']]\n",
    "df.boxplot(by='day_of_week', column=['duration_s'], figsize=(12, 6), grid=False);\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Duration histogram with all outliers with frequency logarithmic scale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "position_xtick = [num for num in range(-25, 400, 25)]\n",
    "df = full_data_df.loc[: , ['duration_s']]/3600\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ax.hist(df['duration_s'], color='orange', bins=100)\n",
    "\n",
    "ax.set_title('durations with all outliers on logarithmic scale', fontsize=30)\n",
    "ax.legend(['duration hours'], fontsize=30, loc='upper center')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_ylabel('frequency [log scale]', fontsize=30)\n",
    "\n",
    "ax.set_xlabel('duration [hrs]', fontsize=30)\n",
    "ax.set_xticks(ticks=position_xtick)\n",
    "\n",
    "plt.show();"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There is 10036 outliers with mean duration time 4.67 hrs.\n",
    "\n",
    "172 stations of origin and 173 destinations generate these values . (Total amount of stations is 199)\n",
    "75% of outliers are within interval <2 hr, 3.73 hrs>.\n",
    "\n",
    "Extreme value is almost 16 days."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "desc = full_data_df['duration_s'].describe()\n",
    "out_hi = desc['75%'] + (desc['75%'] + desc['25%']) * 1.5\n",
    "out_low = desc['25%'] - (desc['75%'] + desc['25%']) * 1.5\n",
    "\n",
    "df = full_data_df.loc[(full_data_df.duration_s > out_hi) | (full_data_df.duration_s < out_low), :]\n",
    "df = df.iloc[:, [1, 4, 11, 13]]\n",
    "\n",
    "(df['duration_s'] / 3600).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('start_out: ', df['start_station_id'].unique().shape[0])\n",
    "print('end_out: ', df['end_station_id'].unique().shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Missing dates**\n",
    "In measured period there should be 776 days but isn't!\n",
    "\n",
    "We can see 22 missing dates bellow:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('full date span: ', (full_data_df.iloc[-1, 0] - full_data_df.iloc[0, 0]).days)\n",
    "df_ = pd.DataFrame(columns=['normalize'])\n",
    "df_['normalize'] = full_data_df['started_at'].dt.normalize()\n",
    "df_u_dates = pd.DataFrame(df_['normalize'].unique())\n",
    "df_u_dates = df_u_dates.rename(columns={0: 'date'})\n",
    "print('Unique dates of rides', df_u_dates.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Weather date measurement span: ', (weather_df.iloc[-1, 0] - weather_df.iloc[0, 0]).days)\n",
    "df_['norm'] = weather_df['date'].dt.normalize()\n",
    "df_u_w = pd.DataFrame(df_['norm'].unique())\n",
    "df_u_w = df_u_dates.rename(columns={0: 'date'})\n",
    "print('Unique dates of weather measurements', df_u_dates.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "missing_dates = []\n",
    "mis_date = bikes_df['started_at'][0].normalize()\n",
    "full_u_list = df_u_dates['date'].to_list()\n",
    "for i in range(776):\n",
    "    if mis_date not in full_u_list:\n",
    "        missing_dates.append(mis_date)\n",
    "    mis_date += pd.DateOffset(1)\n",
    "missing_dates = pd.DataFrame(missing_dates)\n",
    "missing_dates.rename(columns={0: 'missing_dates'}, inplace=True)\n",
    "missing_dates.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Weather during missing days is varied. So missing dates are not weather dependent."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "missing_weather_df = pd.DataFrame(weather_df.loc[weather_df['date'].dt.date == missing_dates['missing_dates'][0].date(), :])\n",
    "for i in range(1, len(missing_dates)):\n",
    "    df = weather_df.loc[weather_df['date'].dt.date == missing_dates['missing_dates'][i].date(), :]\n",
    "    missing_weather_df = missing_weather_df.append(df)\n",
    "missing_weather_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Active and non-active stations**\n",
    "\n",
    "active station criterion:\n",
    "\n",
    "1. over busy   - outliers (13 stations)\n",
    "2. very busy   - qiii + 1.5Q (36 stations)\n",
    "3. busy        - Q (99 stations)\n",
    "4. no busy     - used between non-active and quartile 0.25 (40 stations)\n",
    "5. non-active  - used 8 times or less (10 stations)\n",
    "\n",
    "Amount of station calculated as stations of origin.\n",
    "Similar method should be used for arrival stations.\n",
    "except for non-active stations (both groups are evaluated)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "stations_starts_df = full_data_df['start_station_id'].value_counts()\n",
    "stations_ends_df = full_data_df['end_station_id'].value_counts()\n",
    "\n",
    "df1 = pd.DataFrame(stations_starts_df).reset_index()\n",
    "df1.columns = ['id', 'start_frequency']\n",
    "\n",
    "df2 = pd.DataFrame(stations_ends_df).reset_index()\n",
    "df2.columns = ['id', 'end_frequency']\n",
    "\n",
    "df = pd.merge(df2, df1, left_on='id', right_on='id', how='left')\n",
    "id_act_desc = df.start_frequency.describe()\n",
    "print(id_act_desc)\n",
    "\n",
    "df.boxplot(\n",
    "    column=['start_frequency', 'end_frequency'],\n",
    "    grid=False,\n",
    "    fontsize=20,\n",
    "    figsize=(12,12))\n",
    "plt.title('Full data set description', fontsize=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "criterion 5:\n",
    "\n",
    "Stations 280 and 242 never was used as START station and only 3times or rather twice as END station\n",
    "plus [241, 299, 365, 964, 1032, 1056, 1057, 1740] stations used less than 8 times\n",
    "There is total 10 non-active stations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['accumulation'] = df['end_frequency'] - df['start_frequency']\n",
    "list1 = df.loc[(df['start_frequency'] < 8) & (df['end_frequency'] < 8), ['id']]\n",
    "print('Criterion 5:\\n')\n",
    "print('list of stations\\n',sorted(list1['id'].tolist()))\n",
    "print('Amount of no busy stations: ', len(list1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cond_1 = (df['start_frequency'] < id_act_desc['25%']) & (df['start_frequency'] >= 8)\n",
    "\n",
    "list1 = df.loc[cond_1, ['id']]\n",
    "print('Criterion 4:\\n')\n",
    "print('list of stations\\n',sorted(list1['id'].tolist()))\n",
    "print('Amount of no busy stations: ', len(list1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cond_1 = (df['start_frequency'] >= id_act_desc['25%']) & (df['start_frequency'] <= id_act_desc['75%'])\n",
    "\n",
    "list1 = df.loc[cond_1, ['id']]\n",
    "print('Criterion 3:\\n')\n",
    "print('list of stations\\n',sorted(list1['id'].tolist()))\n",
    "print('Amount of busy stations: ', len(list1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q_range = id_act_desc['75%'] - id_act_desc['25%']\n",
    "cond_1 = (df['start_frequency'] > id_act_desc['75%']) & (df['start_frequency'] <= (id_act_desc['75%'] + 1.5 * q_range))\n",
    "list1 = df.loc[cond_1, ['id']]\n",
    "print('Criterion 2:\\n')\n",
    "print('list of stations\\n',sorted(list1['id'].tolist()))\n",
    "print('Amount of very busy stations: ', len(list1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q_range = id_act_desc['75%'] - id_act_desc['25%']\n",
    "cond_1 = (df['start_frequency'] > (id_act_desc['75%'] + 1.5 * q_range))\n",
    "list1 = df.loc[cond_1, ['id']]\n",
    "print('Criterion 1:\\n')\n",
    "print('list of stations\\n',sorted(list1['id'].tolist()))\n",
    "print('Amount of over busy stations: ', len(list1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**elevation**\n",
    "\n",
    "1. 75% rides are done with difference elevation less than 7m\n",
    "2. 68% rides are within delta interval < -35m, +23m>\n",
    "3. Interquartile range for delta elevation is Q=27 m.\n",
    "4. Outliers delta elev more than 88m or less than -101m (based on <qi + Q, qiii + Q>)\n",
    "5. With 95% probability, riders ride with elevation defferences between <-64m, 52m>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Description of stations elevation: \\n', stations_id_df.elev.describe())\n",
    "print('\\nDescription of delta elevation: \\n', full_data_df.delta_elev.describe())\n",
    "print('\\nAmount of journeys with delta elevation 64m and less: ', bikes_df.loc[bikes_df['delta_elev'] <= -64, ['delta_elev']].count()[0])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\n",
    "**DEMAND**\n",
    "\n",
    "Demand is calculated as bikes usage or station usage per period, basically per day then per week and month\n",
    "\n",
    "data grouped on daily bases looks:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ag_full_df = full_data_df.set_index('wx_date').groupby(pd.Grouper(freq='D'))\\\n",
    "    .agg({\n",
    "    'day_of_week': 'max', 'start_station_id': 'count',\n",
    "    'delta_elev': 'mean', 'dist_km': 'mean', 'duration_s': 'mean', 'heading_deg': 'median',\n",
    "    'wind_direction_deg': 'median', 'gust_km_h': 'mean',\n",
    "    'feels_c': 'mean', 'rain_mm': 'mean'})\\\n",
    "    .reset_index()\\\n",
    "    .rename(columns={'start_station_id': 'start_freq'})\n",
    "\n",
    "ag_full_df.head(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next chart shows:\n",
    "\n",
    "aggregated normalized data due to trend comparison\n",
    "\n",
    "28 days rolling average of weather parameters by demand due to season effect\n",
    "\n",
    "There is strong correlation between demand and temperature and wind speed.\n",
    "Rain has no effect on demand unless above outlier values.\n",
    "\n",
    "During summer 2020 - big grow of demand - may be lockdown effect?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = ag_full_df.set_index('wx_date').rolling(28).mean().dropna()\n",
    "df = (df-df.mean())/df.std()\n",
    "df = df.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.set_title('NORMALIZED data by STD and MEAN', fontsize=40)\n",
    "\n",
    "ax.set_xlabel('date', fontsize=20)\n",
    "ax.tick_params(axis='x', which='major', labelsize=15)\n",
    "ax.grid(b=True, which='major', axis='y', linewidth='2', alpha=0.5)\n",
    "\n",
    "ax.set_ylabel('normalized data', fontsize=20)\n",
    "\n",
    "ax.plot(df['wx_date'], df['start_freq'], color='k', linewidth='10', label='demand')\n",
    "\n",
    "ax.plot(df['wx_date'], df['feels_c'], color='r', linewidth='5', alpha=0.5, label='temperature')\n",
    "ax.plot(df['wx_date'], df['rain_mm'], color='b', linewidth='2', alpha=0.5, label='rain')\n",
    "ax.plot(df['wx_date'], df['gust_km_h'], color='g', linewidth='2', alpha=0.5, label='wind')\n",
    "ax.legend(fontsize=20)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Demand by stations**\n",
    "\n",
    "Aggregated demand dataset of all stations\n",
    "\n",
    "for every station:\n",
    "- calculation of station usage by period of week\n",
    "- then calculation of total sum, min, max, mean, std rolling by 4 weeks of demand\n",
    "- ratio = start demand / end demand:\n",
    "    - ratio > 1 => station represents mostly departure station (mean elev 80m)\n",
    "    - ratio < 1 => station represents mostly destination (mean elev 40 m)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "df1 = full_data_df\\\n",
    "    .groupby([pd.Grouper(key='wx_date', freq='D'), 'start_station_id'])\\\n",
    "    .agg({'start_station_id': 'count', 'feels_c': 'mean'})\\\n",
    "    .rename(columns={'start_station_id': 'freq'}).reset_index()\n",
    "\n",
    "df2 = full_data_df\\\n",
    "    .groupby([pd.Grouper(key='wx_date', freq='D'), 'end_station_id'])\\\n",
    "    .agg({'end_station_id': 'count', 'feels_c': 'mean'})\\\n",
    "    .rename(columns={'end_station_id': 'freq'}).reset_index()\n",
    "\n",
    "df1['freq'] = df1['freq'] * -1\n",
    "\n",
    "station_list = list(stations_id_df['station_id'])\n",
    "result_df = pd.DataFrame()\n",
    "ratio_dict = {}\n",
    "for index, spot in enumerate(station_list):\n",
    "    df11 = df1.loc[df1['start_station_id'] == spot, ['wx_date', 'start_station_id', 'freq', 'feels_c']].rename(columns={'start_station_id': 'id'})\n",
    "    df22 = df2.loc[df2['end_station_id'] == spot, ['wx_date', 'end_station_id', 'freq', 'feels_c']].rename(columns={'end_station_id': 'id'})\n",
    "    df = pd.concat([df11, df22], axis=0)\n",
    "\n",
    "    ratio = abs(df11.freq.sum() / df22.freq.sum())\n",
    "    ratio_dict.update({spot: ratio})\n",
    "\n",
    "    result_df[spot] = df.groupby(pd.Grouper(key='wx_date', freq='W'))\\\n",
    "        .agg({'freq': ['sum', 'min', 'max', 'mean', 'std']})\\\n",
    "        .rolling(4).mean().dropna().mean()\n",
    "\n",
    "result_df = result_df.T.dropna()\n",
    "\n",
    "ratio_df = pd.DataFrame(pd.Series(ratio_dict))\n",
    "result_df = pd.merge(result_df, ratio_df, left_index=True, right_index=True).rename(columns={0: 'ratio'})\n",
    "\n",
    "elev_dict = pd.Series(stations_id_df['elev']\n",
    "                      .values, index=stations_id_df.station_id).to_dict()\n",
    "result_df = result_df.reset_index()\n",
    "result_df['elev'] = result_df['index'].map(elev_dict)\n",
    "result_df = result_df.set_index('index')\n",
    "\n",
    "result_df.rename(columns={('freq', 'sum'): 'week_sum_demand',\n",
    "                          ('freq', 'min'): 'week_min_demand',\n",
    "                          ('freq', 'max'): 'week_max_demand',\n",
    "                          ('freq', 'mean'): 'week_mean_demand',\n",
    "                          ('freq', 'std'): 'week_std_demand'}, inplace='True')\n",
    "result_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_1 = result_df.loc[result_df['ratio'] >= 1, ['elev', 'ratio']]\n",
    "a = pd.DataFrame(df_1['elev'].describe())\n",
    "a.style.set_caption('stations of origin')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_2 = result_df.loc[result_df['ratio'] < 1, ['elev', 'ratio']]\n",
    "a = pd.DataFrame(df_2['elev'].describe())\n",
    "a.style.set_caption('stations of termination')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "__there are 2 types of stations:__\n",
    "- stations non-self regulated with average week ratio demand below or above 1 and high std (above 5...)\n",
    "- self controlled stations with no regulation required (example ID: 349, 171 => ratio around 1 and low STD in week demand)\n",
    "\n",
    "stations below elevation 40m and above 80m need ALWAYS regulation =>\n",
    "higher elevation are lack of bikes (250 vs 290) and vice versa."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "ax.scatter(df_1['elev'], df_1['ratio'], color='r', label='mostly stations of origin, median elevation 80m')\n",
    "ax.scatter(df_2['elev'], df_2['ratio'], color='b', label='mostly destinations, median elevation 40m')\n",
    "\n",
    "ax.set_title(\"Stations' usage\", fontsize='30')\n",
    "ax.set_xlabel('elevation [m]', fontsize=20)\n",
    "ax.set_ylabel('ratio [-]', fontsize=20)\n",
    "ax.set_yticks([1])\n",
    "ax.set_xticks([0, 40, 80, 104])\n",
    "ax.tick_params(labelsize=20, grid_linewidth=2)\n",
    "ax.grid(True)\n",
    "ax.legend(fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now data are grouped by day and by station and for every station is calculated how many bikes are cumulating:\n",
    "- minus means lack of bikes\n",
    "- plus means surplus\n",
    "\n",
    "Temperature is used as peak season indicator\n",
    "\n",
    "week period is used for smoothing curve plotting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# grafy 2x2 a ukazat nutnost modelu pro kazdou stanici (349, 171, 250, 290)\n",
    "df1 = full_data_df\\\n",
    "    .groupby([pd.Grouper(key='wx_date', freq='D'), 'start_station_id'])\\\n",
    "    .agg({'start_station_id': 'count', 'feels_c': 'mean'})\\\n",
    "    .rename(columns={'start_station_id': 'freq'}).reset_index()\n",
    "\n",
    "df2 = full_data_df\\\n",
    "    .groupby([pd.Grouper(key='wx_date', freq='D'), 'end_station_id'])\\\n",
    "    .agg({'end_station_id': 'count', 'feels_c': 'mean'})\\\n",
    "    .rename(columns={'end_station_id': 'freq'}).reset_index()\n",
    "\n",
    "df1['freq'] = df1['freq'] * -1\n",
    "\n",
    "spot = 171\n",
    "df11 = df1.loc[df1['start_station_id'] == spot, ['wx_date', 'start_station_id', 'freq', 'feels_c']].rename(columns={'start_station_id': 'id'})\n",
    "df22 = df2.loc[df2['end_station_id'] == spot, ['wx_date', 'end_station_id', 'freq', 'feels_c']].rename(columns={'end_station_id': 'id'})\n",
    "\n",
    "df = pd.concat([df11, df22], axis=0)\n",
    "df0 = df.groupby(pd.Grouper(key='wx_date', freq='W'))\\\n",
    "    .agg({'freq': 'sum', 'feels_c': 'mean'})\\\n",
    "    .rolling(7).mean().dropna().reset_index()\n",
    "df0.plot(x='wx_date', y=['freq', 'feels_c'], figsize=(12, 6), grid=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FOURTH - CONCLUSION\n",
    "Bikes re-destribution model must be function:\n",
    "- season (priority warm season, logistic service will be more busy)\n",
    "- elevation (lower stations will accumulate bikes and higher are lack of bikes - transfer more uphills)\n",
    "- rain (Threshold can be 0.38 mm/hr or 0.8 mm/hr)\n",
    "- wind speed\n",
    "\n",
    "About data\n",
    "- 22 last days of month are missing. Data collection error? Issue is not caused by weather.\n",
    "- 10 stations are rarely used - adepts to be removed from offer\n",
    "[964, 365, 1057, 1056, 1032, 299, 241, 1740, 280, 242]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bikes_df.to_csv('tables/bikes.csv', sep='\\t')\n",
    "weather_df.to_csv('tables/weather.csv', sep='\\t')\n",
    "stations_id_df.to_csv('tables/stations_id.csv', sep='\\t')\n",
    "full_data_df.to_csv('tables/full_data.csv', sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}